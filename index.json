[{"authors":["admin"],"categories":null,"content":"I am currently a master student in Computer Science and Technology at the School of Data and Computer Science(SDCS), Sun Yat-Sen University(SYSU) under the supervision of Prof. Cheng Hui. I received my bachelor\u0026rsquo;s degree in Software Engineering from SYSU in 2018.\n","date":1601510400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1601510400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://david-willo.github.io/author/jinhao-he/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jinhao-he/","section":"authors","summary":"I am currently a master student in Computer Science and Technology at the School of Data and Computer Science(SDCS), Sun Yat-Sen University(SYSU) under the supervision of Prof. Cheng Hui. I received my bachelor\u0026rsquo;s degree in Software Engineering from SYSU in 2018.","tags":null,"title":"Jinhao He","type":"authors"},{"authors":["Jinhao He","Yuming Zhou","Lixiang Huang","Yang Kong","Hui Cheng"],"categories":null,"content":"   --  -- ","date":1603238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603238400,"objectID":"4fc12b49e973f6921cf6ed7dc0400d40","permalink":"http://david-willo.github.io/publication/he-ground-2020/","publishdate":"2020-10-21T06:16:02.002097Z","relpermalink":"/publication/he-ground-2020/","section":"publication","summary":"A heterogeneous multi-robot system consisting of Unmanned Ground Vehicles (UGVs) and Unmanned Aerial Vehicles (UAVs) have advantages over a single-robot system in efficiency and flexibility, enabling them to perform a larger range of tasks. To allow heterogeneous platforms to work together in GPS-denied scenarios, it is crucial to build a complete 3D map of the environment. In this paper, a novel method is presented to perform ground and aerial collaborative mapping leveraging visual and range data collected by cameras and 3D LiDAR sensors. In the proposed system, a visual-LiDAR ego-motion estimation module that considers point, line and planar constraints can provide robust odometry information. Thumbnail images representing obstacle outlines are generated and descriptors are extracted using a neural network to help perform data association between separate runs. Map segments and the robot poses are organized together and are updated during a pose graph optimization procedure. The proposed ground-aerial collaborative mapping approach is evaluated on both synthetic and real-world datasets comparing with other methods. Experiment results demonstrate that our method can achieve outstanding mapping results.","tags":[],"title":"Ground and Aerial Collaborative Mapping in Urban Environments","type":"publication"},{"authors":["Jinhao He"],"categories":null,"content":"One paper Ground and Aerial Collaborative Mapping in Urban Environments has been accepted by IEEE Robotics and Automation Letters (RA-L).\n","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"8d083e2aaf6e75597547605d21459014","permalink":"http://david-willo.github.io/post/news/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/post/news/","section":"post","summary":"One paper has been accepted by IEEE Robotics and Automation Letters.","tags":null,"title":"One paper has been accepted by IEEE Robotics and Automation Letters","type":"post"},{"authors":[],"categories":[],"content":"A system that uses heterogeneous platforms(cars and drones) mounted with 16-beam LiDARs and RGB cameras to build a 3D point cloud map of the environment.\n ","date":1595252659,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595252659,"objectID":"30a45c3c5427df7b63f9a7915d19cd52","permalink":"http://david-willo.github.io/project/ground_n_aerial_collaborative_mapping_in_urban_environment/","publishdate":"2020-07-20T21:44:19+08:00","relpermalink":"/project/ground_n_aerial_collaborative_mapping_in_urban_environment/","section":"project","summary":"A system that uses heterogeneous platforms(cars and drones) mounted with 16-beam LiDARs and RGB cameras to build a 3D point cloud map of the environment.\n ","tags":[],"title":"Ground and Aerial Collaborative Mapping in Urban Environments","type":"project"},{"authors":[],"categories":[],"content":"A Visual-LiDAR SLAM system considering both point, line and planar constraints. This system employ multi-sensor fusion and dense mapping in a same pipeline, which is robust under degenerated scenarios.  ","date":1595251519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595251519,"objectID":"4a5f3cfe48f704093bcbb597a99bae6f","permalink":"http://david-willo.github.io/project/structure_awared_vlo_n_dense_mapping/","publishdate":"2020-07-20T21:25:19+08:00","relpermalink":"/project/structure_awared_vlo_n_dense_mapping/","section":"project","summary":"A Visual-LiDAR SLAM system considering both point, line and planar constraints. This system employ multi-sensor fusion and dense mapping in a same pipeline, which is robust under degenerated scenarios.  ","tags":[],"title":"Structure-awared Visual-LiDAR Odometry and Dense Mapping","type":"project"},{"authors":["Xuanbo Liu","Jinhao He","Hui Cheng"],"categories":null,"content":"","date":1569715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569715200,"objectID":"206d3b0f59142c20308056e44d76765c","permalink":"http://david-willo.github.io/patent/map-fusion-method/","publishdate":"2020-07-20T06:16:02.002697Z","relpermalink":"/patent/map-fusion-method/","section":"patent","summary":"The invention relates to the technical field of map fusion, in particular to a map fusion method suitable for a sub-map with few overlapping parts. The method comprises: firstly, iteratively calculating a rotation matrix R by using point cloud plane extraction, normal vector estimation and normal vector projection angle statistics methods, then iteratively transforming source point clouds by usingthe R, finally, performing three-view projection on the two groups of point clouds to obtain two groups of grey-scale maps, and calculating a translation vector t by using a phase correlation methodfor the grey-scale maps; and finally obtaining a transformation matrix (R, t) between the two groups of point clouds. According to the map fusion method suitable for a sub-map with few overlapping parts, the fusion of the sub-maps under the low overlapping degree can be correctly completed, the error of searching corresponding points by the previous methods is avoided, and the method is suitable for the registration between two groups of large map point clouds with fewer overlapping parts and three axes having rotating angles at the same time.","tags":[],"title":"Map fusion method suitable for sub-map with few overlapping parts","type":"patent"},{"authors":[],"categories":[],"content":"  Time-synchronized simulation sensor data including LiDAR point cloud, stereo RGB images as well as IMU(Inertial Measurement Unit) data from multiple robots are recorded into ROS bags, which is sufficient for simulation tests for multi-robot SLAM systems.\n","date":1563626590,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563626590,"objectID":"08203eeccd1d6eaaf22f17912b2e53bb","permalink":"http://david-willo.github.io/project/synthetic_data_generation_for_multi_robot_slam/","publishdate":"2019-07-20T20:43:10+08:00","relpermalink":"/project/synthetic_data_generation_for_multi_robot_slam/","section":"project","summary":"Time-synchronized simulation sensor data including LiDAR point cloud, stereo RGB images as well as IMU(Inertial Measurement Unit) data from multiple robots are recorded into ROS bags, which is sufficient for simulation tests for multi-robot SLAM systems.","tags":[],"title":"Synthetic Data Generation for Multi-Robot SLAM","type":"project"},{"authors":[],"categories":[],"content":"A system that uses multiple robots mounted with 16-beam LiDARs to build a 3D point cloud map of the environment.  ","date":1561032654,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561032654,"objectID":"70ef1e7cc7fed9fa07092408db3b3c82","permalink":"http://david-willo.github.io/project/lidar_based_collaborative_localization_and_mapping/","publishdate":"2019-06-20T20:10:54+08:00","relpermalink":"/project/lidar_based_collaborative_localization_and_mapping/","section":"project","summary":"A system that uses multiple robots mounted with 16-beam LiDARs to build a 3D point cloud map of the environment.  ","tags":[],"title":"LiDAR-based Collaborative Localization and Mapping","type":"project"},{"authors":["Yongheng Hu","Hui Cheng","Jinhao He","Yang Kong"],"categories":null,"content":"","date":1552608000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552608000,"objectID":"8f2b23d6cc889fda9f74ee0ac686c6d8","permalink":"http://david-willo.github.io/patent/multi-unmanned-platform-synchronous-positioning-and-map-construction/","publishdate":"2020-07-20T06:16:02.002397Z","relpermalink":"/patent/multi-unmanned-platform-synchronous-positioning-and-map-construction/","section":"patent","summary":" The invention relates to a multi-unmanned-platform synchronous positioning and map construction method under limitation of communication bandwidth and distance. The method comprises: constructing a plurality of unmanned platform systems with ArUco tags and carrying out own-side target detection and own-side target relative attitude estimation by using a visual system; on the basis of a hand-eye calibration method, carrying out conversion into a relative pose under a visual system coordinate system and converting the relative pose into a radar coordinate system by using external parameters calibrated by a camera and a radar; carrying out communication only between unmanned systems generating a closed loop after detection of the own-side target and carrying out joint pose map construction and optimization by an active loopback unmanned system terminal; optimizing the pose at an active loopback terminal to realize expression of poses of different robots under the same coordinate system, acquiring an accurate pose, and then sending the accurate pose to an active loopback unmanned platform; and after recycling of the unmanned systems, transmitting all independent unmanned system maps tothe central platform and carrying out fusion. Therefore, a cooperative SLAM problem under limitation of the communication distance and communication limitation is solved.","tags":[],"title":"Multi-unmanned-platform synchronous positioning and map construction method under limitation of communication bandwidth and distance","type":"patent"},{"authors":["Hui Cheng","Zhuoqi Zheng","Jinhao He","Chongyu Chen","Keze Wang","Liang Lin"],"categories":null,"content":"A method to embed depth recovery algorithm into VIO-based sparse visual SLAM system for real-time dense mapping.\n A subspace-based stabilization scheme to maintain the temporal consistency of visual landmarks. A hierarchical pipeline for edge-preserving depth interpolation. The whole pipeline is implemented using CPU only.         --  -- ","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"9c06f525f2d6233bb50724a31853bd58","permalink":"http://david-willo.github.io/project/cheng-embedding-2018/","publishdate":"2020-07-20T06:16:02.002097Z","relpermalink":"/project/cheng-embedding-2018/","section":"project","summary":"Dense mapping is always the desire of simultaneous localization and mapping (SLAM), especially for the applications that require fast and dense scene information. Visual-inertial odometry (VIO) is a light-weight and effective solution to fast self-localization. However, VIO-based SLAM systems have difficulty in providing dense mapping results due to the spatial sparsity and temporal instability of the VIO depth estimations. Although there have been great efforts on real-time mapping and depth recovery from sparse measurements, the existing solutions for VIO-based SLAM still fail to preserve sufficient geometry details in their results. In this paper, we propose to embed depth recovery into VIO-based SLAM for real-time dense mapping. In the proposed method, we present a subspace-based stabilization scheme to maintain the temporal consistency and design a hierarchical pipeline for edge-preserving depth interpolation to reduce the computational burden. Numerous experiments demonstrate that our method can achieve an accuracy improvement of up to 49.1 cm compared to state-of-the-art learning-based methods for depth recovery and reconstruct sufficient geometric details in dense mapping when only 0.07% depth samples are available. Since a simple CPU implementation of our method already runs at 10-20 fps, we believe our method is very favorable for practical SLAM systems with critical computational requirements.","tags":[],"title":"Embedding Temporally Consistent Depth Recovery for Real-time Dense Mapping in Visual-inertial Odometry","type":"project"},{"authors":["Hui Cheng","Zhuoqi Zheng","Jinhao He","Chongyu Chen","Keze Wang","Liang Lin"],"categories":null,"content":"      --  -- ","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"e19840a37cfc781f23e6a9fce4ea4390","permalink":"http://david-willo.github.io/publication/cheng-embedding-2018/","publishdate":"2020-07-20T06:16:02.002097Z","relpermalink":"/publication/cheng-embedding-2018/","section":"publication","summary":"Dense mapping is always the desire of simultaneous localization and mapping (SLAM), especially for the applications that require fast and dense scene information. Visual-inertial odometry (VIO) is a light-weight and effective solution to fast self-localization. However, VIO-based SLAM systems have difficulty in providing dense mapping results due to the spatial sparsity and temporal instability of the VIO depth estimations. Although there have been great efforts on real-time mapping and depth recovery from sparse measurements, the existing solutions for VIO-based SLAM still fail to preserve sufficient geometry details in their results. In this paper, we propose to embed depth recovery into VIO-based SLAM for real-time dense mapping. In the proposed method, we present a subspace-based stabilization scheme to maintain the temporal consistency and design a hierarchical pipeline for edge-preserving depth interpolation to reduce the computational burden. Numerous experiments demonstrate that our method can achieve an accuracy improvement of up to 49.1 cm compared to state-of-the-art learning-based methods for depth recovery and reconstruct sufficient geometric details in dense mapping when only 0.07% depth samples are available. Since a simple CPU implementation of our method already runs at 10-20 fps, we believe our method is very favorable for practical SLAM systems with critical computational requirements.","tags":[],"title":"Embedding Temporally Consistent Depth Recovery for Real-time Dense Mapping in Visual-inertial Odometry","type":"publication"},{"authors":[],"categories":[],"content":"A system to help users to localize themselves in a shopping center using a smart phone.\n Image frames and gyroscope data are captured and upload to the server using an Android app. Detect and track shop signs on image sequence. Compute the positioning result and send it back to the user front-end.    ","date":1515568582,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515568582,"objectID":"6aea0a1f211984c69b409db4891b0948","permalink":"http://david-willo.github.io/project/an-in-door-positioning-system-on-smart-phones/","publishdate":"2018-01-10T15:16:22+08:00","relpermalink":"/project/an-in-door-positioning-system-on-smart-phones/","section":"project","summary":"A system to help users to localize themselves in a shopping center using a smart phone.\n Image frames and gyroscope data are captured and upload to the server using an Android app.","tags":[],"title":"An Indoor Positioning System On Smart Phones","type":"project"},{"authors":["Hui Cheng","Zhuoqi Zheng","Jinhao He","Chongyu Chen"],"categories":null,"content":"","date":1513900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513900800,"objectID":"c1e67b00ae759d7c3711fa15d872ceb9","permalink":"http://david-willo.github.io/patent/quick-depth-restoring/","publishdate":"2020-07-20T06:16:02.002697Z","relpermalink":"/patent/quick-depth-restoring/","section":"patent","summary":"The invention relates to the technical field of stereo vision in computer vision, and particularly to a depth restoring method for three-dimensional reconstruction. After depths of sparse characteristic points in an image are obtained through a structure from motion (SFM), depth is diffused based on the sparse characteristic points and a gray scale image through multilayer down-sampling and a double-side filter. An accurate depth map is quickly restored from low resolution to high resolution and from rough to fine in a layered manner. The method has advantages of accurate result and low calculating amount. The sparse characteristic points which are obtained through calculation in the system can be restored to the dense depth map by means of a simultaneous localization and mapping (SLAM) system based on a characteristic point method, thereby reconstructing the three-dimensional dense map.","tags":[],"title":"Quick depth restoring method for three-dimensional reconstruction","type":"patent"},{"authors":[],"categories":[],"content":"A hybrid solution integrating the features of adaptive sensor fusion, robust loss function, and consistent sparsification into a visual-inertial odometry (VIO) system, improving the system\u0026rsquo;s accuracy, robustness, and efficiency respectively.\n Switchable Constraints and Dynamic Covariance Scaling loss is use in visual residual to improve the robustness of the VIO system The weights of inertial residuals are adjusted adaptively according to the motion states of the system the marginalized information matrix is consistently sparsified to reduce the fill-in effect  ","date":1505907817,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505907817,"objectID":"ec658c3443e88fe350fc363b26f8a5b4","permalink":"http://david-willo.github.io/project/robust_visual_inertial_odometry_with_consistent_sparsification/","publishdate":"2017-09-20T19:43:37+08:00","relpermalink":"/project/robust_visual_inertial_odometry_with_consistent_sparsification/","section":"project","summary":"A hybrid solution integrating the features of adaptive sensor fusion, robust loss function, and consistent sparsification into a visual-inertial odometry (VIO) system, improving the system\u0026rsquo;s accuracy, robustness, and efficiency respectively.","tags":[],"title":"Robust Visual Inertial Odometry With Consistent Sparsification","type":"project"}]